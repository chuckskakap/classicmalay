{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model and tokenizer...\n",
      "\n",
      "Testing base model (before fine-tuning):\n",
      "\n",
      "Testing generation...\n",
      "\n",
      "Prompt: My trip to Kuala Lumpur was so annoying\n",
      "Generated text: My trip to Kuala Lumpur was so annoying, I had to go to the airport to get my passport. I was told that I had to go to the airport to get my passport. I was told that I had to go to the airport to get my passport. I was told that I had to go to the airport to get my passport. I was told that I had to go to the airport to get my passport. I was told that I had to go to the airport to get my passport. I was told that I had to go to the airport to get my passport. I was told that I had to go to the airport to get my passport. I was told that I had to go to the airport to get my passport. I was told that I had to go to the airport to get my passport. I was told that I had to go to the airport to get my passport. I was told that I had to go to the airport to get my passport. I was told\n",
      "\n",
      "Loading data for fine-tuning...\n",
      "      subheading                                             pantun  \\\n",
      "0   mukaddimah_a  Tetak buluh panjang suluh,\\r\\nMari jolok saran...   \n",
      "1   mukaddimah_b  Tetak buluh panjang suluh,\\r\\nMari jolok saran...   \n",
      "2    hikayat_1_a  Medang sila buahnya cantik,\\r\\nJatuh menimpa k...   \n",
      "3    hikayat_2_a  Hendak mencari si ikan belida,\\r\\nTerpancing p...   \n",
      "4    hikayat_2_b  Hendak mencari si ikan belida,\\r\\nTerpancing p...   \n",
      "..           ...                                                ...   \n",
      "82  hikayat_29_b  Baik-baik mengirai padi,\\r\\nTakut mercik ke mu...   \n",
      "83  hikayat_29_c  Baik-baik mengirai padi,\\r\\nTakut mercik ke mu...   \n",
      "84  hikayat_29_d  Baik-baik mengirai padi,\\r\\nTakut mercik ke mu...   \n",
      "85  hikayat_29_e  Baik-baik mengirai padi,\\r\\nTakut mercik ke mu...   \n",
      "86    khatimah_a  Tinggi bukit gilang-gemilang,\\r\\nAir laut tena...   \n",
      "\n",
      "                                              content  \n",
      "0   Dia ternganga. Tidak menyangka akan ditinggalk...  \n",
      "1   Angin menderu-deru, biasan pertembungan antara...  \n",
      "2    “Di manakah budak itu?” \\nBagai halilintar, s...  \n",
      "3   Api marak meliang-liuk diserbu angin, menerang...  \n",
      "4   “Allahu akbar.”\\r\\n\\tJeda sedetik.\\r\\n\\t“Attah...  \n",
      "..                                                ...  \n",
      "82  “Engkau tidak biasa bertarung dengan mata tert...  \n",
      "83  “Lemah!” \\r\\nNujum Surya menghantar Cendana me...  \n",
      "84  Medan pertempuran semakin tenang. Tentera Inde...  \n",
      "85  Nirnama tidak lagi berbaju. Yang tinggal hanya...  \n",
      "86  Angin sepoi-sepoi bahasa membelai tubuh, umpam...  \n",
      "\n",
      "[87 rows x 3 columns]\n",
      "      subheading                                             pantun  \\\n",
      "0   mukaddimah_a  Tetak buluh panjang suluh,\\r\\nMari jolok saran...   \n",
      "1   mukaddimah_b  Tetak buluh panjang suluh,\\r\\nMari jolok saran...   \n",
      "2    hikayat_1_a  Medang sila buahnya cantik,\\r\\nJatuh menimpa k...   \n",
      "3    hikayat_2_a  Hendak mencari si ikan belida,\\r\\nTerpancing p...   \n",
      "4    hikayat_2_b  Hendak mencari si ikan belida,\\r\\nTerpancing p...   \n",
      "..           ...                                                ...   \n",
      "82  hikayat_29_b  Baik-baik mengirai padi,\\r\\nTakut mercik ke mu...   \n",
      "83  hikayat_29_c  Baik-baik mengirai padi,\\r\\nTakut mercik ke mu...   \n",
      "84  hikayat_29_d  Baik-baik mengirai padi,\\r\\nTakut mercik ke mu...   \n",
      "85  hikayat_29_e  Baik-baik mengirai padi,\\r\\nTakut mercik ke mu...   \n",
      "86    khatimah_a  Tinggi bukit gilang-gemilang,\\r\\nAir laut tena...   \n",
      "\n",
      "                                              content  \n",
      "0   dia ternganga. tidak menyangka akan ditinggalk...  \n",
      "1   angin menderu-deru, biasan pertembungan antara...  \n",
      "2   “di manakah budak itu?”  bagai halilintar, sua...  \n",
      "3   api marak meliang-liuk diserbu angin, menerang...  \n",
      "4   “allahu akbar.”  jeda sedetik.  “attahiyyatul ...  \n",
      "..                                                ...  \n",
      "82  “engkau tidak biasa bertarung dengan mata tert...  \n",
      "83  “lemah!”  nujum surya menghantar cendana melay...  \n",
      "84  medan pertempuran semakin tenang. tentera inde...  \n",
      "85  nirnama tidak lagi berbaju. yang tinggal hanya...  \n",
      "86  angin sepoi-sepoi bahasa membelai tubuh, umpam...  \n",
      "\n",
      "[87 rows x 3 columns]\n",
      "Preparing dataset...\n",
      "Starting fine-tuning...\n",
      "Epoch 1/15 completed with loss: 4.377250671386719\n",
      "Epoch 2/15 completed with loss: 3.6313974857330322\n",
      "Epoch 3/15 completed with loss: 3.246429681777954\n",
      "Epoch 4/15 completed with loss: 2.9486711025238037\n",
      "Epoch 5/15 completed with loss: 2.6168556213378906\n",
      "Epoch 6/15 completed with loss: 2.5922765731811523\n",
      "Epoch 7/15 completed with loss: 2.419231414794922\n",
      "Epoch 8/15 completed with loss: 2.2307612895965576\n",
      "Epoch 9/15 completed with loss: 1.9997100830078125\n",
      "Epoch 10/15 completed with loss: 1.9304134845733643\n",
      "Epoch 11/15 completed with loss: 1.8303841352462769\n",
      "Epoch 12/15 completed with loss: 1.6846494674682617\n",
      "Epoch 13/15 completed with loss: 1.5924886465072632\n",
      "Epoch 14/15 completed with loss: 1.4700042009353638\n",
      "Epoch 15/15 completed with loss: 1.494678258895874\n",
      "Training completed in 711.60 seconds\n",
      "\n",
      "Testing fine-tuned model:\n",
      "\n",
      "Testing generation...\n",
      "\n",
      "Prompt: Raja dan puterinya melangkah\n",
      "Generated text: Raja dan puterinya melangkah lagi berbaju. perkarangan-karang melayangkan dia puteri gunung ledang. sepertiga angin, dia memerhatikan kecederaan. semua itu tidak lagi terpaksaikan pertaronan.  “aku dibesarkan kucar-kacirikan jugaan mewah. apakah engkaukan dalam?”  “aku dibesarkan kucar-kaciran jugaan.”  “engkau telah berada di sini, juga?”  “aku dalam?”  “aku dibesarkan kucar-kacir dengan jugaan menerima.”  “aku dalam?”  “aku d\n",
      "\n",
      "Saving fine-tuned model...\n",
      "Model and tokenizer saved successfully to ./classicmalaymodel\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to load and preprocess data\n",
    "def load_data(gsheet_id, sheet_name):\n",
    "    \"\"\"Load data from Google Sheets and preprocess it\"\"\"\n",
    "    gsheet_url = f\"https://docs.google.com/spreadsheets/d/{gsheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
    "    try:\n",
    "        df = pd.read_csv(gsheet_url)\n",
    "        df = df.iloc[:, 0:3]  # Keep only first 3 columns\n",
    "        print(df)\n",
    "        \n",
    "        # Clean text content\n",
    "        df['content'] = (df['content'].str.lower()\n",
    "                        .str.replace('\\r\\n', ' ', regex=False)\n",
    "                        .str.replace('\\t', ' ', regex=False)\n",
    "                        .str.replace('\\n', ' ', regex=False)\n",
    "                        .str.replace('       ', ' ', regex=False)\n",
    "                        .str.strip())\n",
    "        print(df)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Custom Dataset class for PyTorch\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length=256):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encodings = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        return encodings.input_ids.squeeze(), encodings.attention_mask.squeeze()\n",
    "\n",
    "\n",
    "def test_generation(model, tokenizer, prompts):\n",
    "    \"\"\"Test model generation with given prompts\"\"\"\n",
    "    print(\"\\nTesting generation...\")\n",
    "\n",
    "    # Ensure model is on the correct device (GPU in this case)\n",
    "    device = model.device\n",
    "    \n",
    "    # Set or add padding token if not already set\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token  # Or add '[PAD]' as pad token\n",
    "\n",
    "    for prompt in prompts:\n",
    "        print(f\"\\nPrompt: {prompt}\")\n",
    "        inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True)\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        input_ids = inputs['input_ids']\n",
    "        \n",
    "        # Move input_ids and attention_mask to the same device as the model\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        \n",
    "        # Generate the output\n",
    "        outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=200, pad_token_id=tokenizer.pad_token_id)\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        print(f\"Generated text: {generated_text}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    \"\"\"Load GPT-2 model and tokenizer from Hugging Face\"\"\"\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    return model, tokenizer\n",
    "\n",
    "def prepare_dataset(texts, tokenizer, batch_size=8):\n",
    "    \"\"\"Prepare dataset for training\"\"\"\n",
    "    dataset = TextDataset(texts, tokenizer)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def save_model(model, tokenizer, base_path=\"./classicmalaymodel\"):\n",
    "    \"\"\"Save model weights and configuration\"\"\"\n",
    "    try:\n",
    "        # Create directory if it doesn't exist\n",
    "        Path(base_path).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Save the model and tokenizer\n",
    "        model.save_pretrained(base_path)\n",
    "        tokenizer.save_pretrained(base_path)\n",
    "        \n",
    "        print(f\"Model and tokenizer saved successfully to {base_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {e}\")\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    GSHEET_ID = \"191YRBsdUEGtgXvWl428L9xt48Ah5zcyoRK1pvNhUDPM\"\n",
    "    SHEET_NAME = \"Sheet1\"\n",
    "    NUM_EPOCHS = 15\n",
    "    BATCH_SIZE = 8\n",
    "    LEARNING_RATE = 3e-4\n",
    "    \n",
    "    # Test prompts\n",
    "    test_prompts_base = [\n",
    "        \"My trip to Kuala Lumpur was so annoying\"\n",
    "    ]\n",
    "    test_prompts_malay = [\n",
    "        \"Raja dan puterinya melangkah\"\n",
    "    ]\n",
    "    \n",
    "    # Create model and tokenizer\n",
    "    print(\"Creating model and tokenizer...\")\n",
    "    model, tokenizer = create_model()\n",
    "    \n",
    "    # Test the base model (before fine-tuning)\n",
    "    print(\"\\nTesting base model (before fine-tuning):\")\n",
    "    test_generation(model, tokenizer, test_prompts_base)\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    print(\"\\nLoading data for fine-tuning...\")\n",
    "    df = load_data(GSHEET_ID, SHEET_NAME)\n",
    "    if df is None:\n",
    "        return\n",
    "    \n",
    "    # Prepare dataset\n",
    "    print(\"Preparing dataset...\")\n",
    "    train_dl = prepare_dataset(df['content'], tokenizer, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    # Prepare optimizer and scheduler\n",
    "    from torch.optim import AdamW\n",
    "    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    total_steps = len(train_dl) * NUM_EPOCHS\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "    \n",
    "    # Move model to GPU if available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    # Fine-tune model\n",
    "    print(\"Starting fine-tuning...\")\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        for batch in train_dl:\n",
    "            input_ids, attention_mask = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS} completed with loss: {loss.item()}\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"Training completed in {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    # Test fine-tuned model\n",
    "    print(\"\\nTesting fine-tuned model:\")\n",
    "    test_generation(model, tokenizer, test_prompts_malay)\n",
    "    \n",
    "    # Save model\n",
    "    print(\"\\nSaving fine-tuned model...\")\n",
    "    save_model(model, tokenizer)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "# Define the directory where the model and tokenizer were saved\n",
    "saved_model_dir = \"./classicmalaymodel\"  # Or wherever you specified when saving\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(saved_model_dir)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(saved_model_dir)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: air lautan kembali ke seluruh penduduk perkampungan gapura persekitaran. persekitaran penduduk perkampungan gapura persekitaran tersebut.  sekali-sekala, sekali-sekala, sekali-sekala, sekali-sekala, sekala-sekala, sekala-sekala, se\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, tokenizer, prompt, max_length=100):\n",
    "    # Encode the prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Generate output\n",
    "    outputs = model.generate(inputs[\"input_ids\"], max_length=max_length, pad_token_id=tokenizer.pad_token_id)\n",
    "    \n",
    "    # Decode the generated tokens into text\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Example prompt\n",
    "prompt = \"air laut\"\n",
    "generated_text = generate_text(model, tokenizer, prompt)\n",
    "print(\"Generated text:\", generated_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (torchgpu)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
